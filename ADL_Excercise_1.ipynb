{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB+OmvaiHe/jSbcEmF38NP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarlundberg95/ADL/blob/main/ADL_Excercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download and prepare CIFAR-10 dataset*\n",
        "\n",
        "**Approach for image recogniztion**\n",
        "* Normalize the image pixel values (divide by 255)\n",
        "* One-Hot Encode the categorical column\n",
        "* Build a model architecture (Sequential) with Dense layers(Fully connected layers)\n",
        "* Train the model and make predictions"
      ],
      "metadata": {
        "id": "SeftxONs7UKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import datetime\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# loading cifar10 and shape + type assert to be sure\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# one-hot encoding categories\n",
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "# normalizing\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "i8YtgpRW7ahM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fab0e8-541a-4945-8da8-ac4b5390d6c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**All the models are the same except for optimizer and activation functions. As well as run with the same batch size of 128 and 10 epochs**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sS-Fwi0W7a64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for TensorBoard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=log_dir, histogram_freq=1)\n",
        "hparams_callback = hp.KerasCallback(log_dir, {\n",
        "    'num_relu_units': 512,\n",
        "    'dropout': 0.2\n",
        "})"
      ],
      "metadata": {
        "id": "6jFEBfj4MWVK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeakyReLU + SGD\n",
        "## Results: val accuracy ~ 9,95%\n"
      ],
      "metadata": {
        "id": "-uEmBGQUd7Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *Write a simple CNN network for classifying images*\n",
        "  - *use LeakyReLU as the activation function*\n",
        "  - *use SGD as the optimizer and 0.0001 as the learning rate, and keep all default param-eters*\n",
        "â€“ *Report the accuracy on the test set*"
      ],
      "metadata": {
        "id": "2p1P97VSfi54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for TensorBoard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# linear stack of layers\n",
        "model = Sequential()\n",
        "# layer 1\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='LeakyReLU', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden + output\n",
        "model.add(Dense(100, activation='LeakyReLU'))\n",
        "model.add(Dense(10, activation='LeakyReLU'))\n",
        "\n",
        "# compiling the model\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# lol\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback, hparams_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koKj8WLCDTrL",
        "outputId": "ee670367-12c8-4ae2-846d-66159f8d9ba2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 7s 16ms/step - loss: 4.9365 - accuracy: 0.0998 - val_loss: 4.8191 - val_accuracy: 0.1021\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 4.7240 - accuracy: 0.1204 - val_loss: 4.6064 - val_accuracy: 0.1398\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 7.1839 - accuracy: 0.1149 - val_loss: 8.2097 - val_accuracy: 0.1001\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 8.4003 - accuracy: 0.1004 - val_loss: 8.4405 - val_accuracy: 0.1008\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.2988 - accuracy: 0.1007 - val_loss: 8.3611 - val_accuracy: 0.1010\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.2305 - accuracy: 0.1008 - val_loss: 8.2529 - val_accuracy: 0.1014\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.2101 - accuracy: 0.1007 - val_loss: 8.1835 - val_accuracy: 0.1016\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 8.1655 - accuracy: 0.1008 - val_loss: 8.1641 - val_accuracy: 0.1016\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 8.1571 - accuracy: 0.1009 - val_loss: 8.1512 - val_accuracy: 0.1019\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.1196 - accuracy: 0.1010 - val_loss: 8.1205 - val_accuracy: 0.1019\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f09e632e0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeakyReLU + Adam\n",
        "## Results: val accuracy ~ 31%\n"
      ],
      "metadata": {
        "id": "uCzzL-VqeBId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Change the optimiser to Adam and run again the experiment. Report accuracy on test set.*\n"
      ],
      "metadata": {
        "id": "Ns5dVNa2DXMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for TensorBoard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# linear stack of layers\n",
        "model = Sequential()\n",
        "# layer 1\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='LeakyReLU', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden + output\n",
        "model.add(Dense(100, activation='LeakyReLU'))\n",
        "model.add(Dense(10, activation='LeakyReLU'))\n",
        "\n",
        "# compiling the model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback, hparams_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jWTcgnvDZh-",
        "outputId": "eac4eb12-396a-4999-b9cb-94ab998efeb0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 8s 14ms/step - loss: 7.9570 - accuracy: 0.1431 - val_loss: 7.8737 - val_accuracy: 0.1377\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 7.9366 - accuracy: 0.1414 - val_loss: 7.8624 - val_accuracy: 0.1391\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.0110 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 8.0139 - accuracy: 0.1441 - val_loss: 7.9075 - val_accuracy: 0.1396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f0a08bca0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tanh + SGD\n",
        "## Results: val accuracy ~ 5%"
      ],
      "metadata": {
        "id": "kLgM6v7SeYc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Swap the LeakyReLUs for Tanh. Then run again the experiment and report accuracy on test set. Make a separate file for this experiment.*\n"
      ],
      "metadata": {
        "id": "PuJVGNDoDcLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for TensorBoard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# linear stack of layers\n",
        "model = Sequential()\n",
        "# layer 1\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='tanh', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden + output\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# compiling the model\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback, hparams_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfJsj-aVDesD",
        "outputId": "5bc6c74f-e688-4915-b422-f163a7a4ff47"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 4.7840 - accuracy: 0.1081 - val_loss: 4.5675 - val_accuracy: 0.1094\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.8754 - accuracy: 0.1062 - val_loss: 8.0518 - val_accuracy: 0.1044\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 7.6307 - accuracy: 0.1038 - val_loss: 6.5523 - val_accuracy: 0.1078\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 7.4729 - accuracy: 0.1061 - val_loss: 7.2520 - val_accuracy: 0.1092\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 8.0357 - accuracy: 0.1044 - val_loss: 7.8707 - val_accuracy: 0.1038\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 7.7936 - accuracy: 0.1038 - val_loss: 7.5815 - val_accuracy: 0.1036\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 7.5138 - accuracy: 0.1025 - val_loss: 6.6050 - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 6.6607 - accuracy: 0.1000 - val_loss: 6.1831 - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 6.5614 - accuracy: 0.1000 - val_loss: 6.6444 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 6.5113 - accuracy: 0.1000 - val_loss: 6.6108 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ed0c37e20>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tanh + Adam\n",
        "## Results: val accuracy ~ 11%"
      ],
      "metadata": {
        "id": "n_qJl7uwepW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging for TensorBoard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# linear stack of layers\n",
        "model = Sequential()\n",
        "# layer 1\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='tanh', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "# hidden + output\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# compiling the model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback, hparams_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4RGEtC2ev00",
        "outputId": "2b14b04f-b3f2-492a-9524-2b9f65d6add0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 7s 14ms/step - loss: 7.4386 - accuracy: 0.1110 - val_loss: 8.0591 - val_accuracy: 0.1108\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.0591 - accuracy: 0.1105 - val_loss: 8.0591 - val_accuracy: 0.1127\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.0591 - accuracy: 0.1112 - val_loss: 8.0590 - val_accuracy: 0.1128\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 8.0591 - accuracy: 0.1114 - val_loss: 8.0590 - val_accuracy: 0.1128\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 8.0591 - accuracy: 0.1114 - val_loss: 8.0590 - val_accuracy: 0.1126\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 8.0591 - accuracy: 0.1116 - val_loss: 8.0590 - val_accuracy: 0.1125\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 8.0590 - accuracy: 0.1116 - val_loss: 8.0590 - val_accuracy: 0.1125\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 8.0590 - accuracy: 0.1116 - val_loss: 8.0590 - val_accuracy: 0.1125\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 8.0591 - accuracy: 0.1116 - val_loss: 8.0590 - val_accuracy: 0.1125\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 8.0590 - accuracy: 0.1116 - val_loss: 8.0590 - val_accuracy: 0.1125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6ed0891670>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualize the results of these runs on a Tensorboard. Just put any screenshot of the web interface with the experiments to prove you got it working is enough. (for example- show the training loss on tensorboard)*"
      ],
      "metadata": {
        "id": "61g1QKW8DfsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear TensorBoard logs\n",
        "!rm -rf /content/logs"
      ],
      "metadata": {
        "id": "3AQzW_KrDgQC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### TO ADD #######################################\n",
        "!tensorboard dev upload --logdir ./logs \\\n",
        "  --name \"test1\" \\\n",
        "  --description \"test1\" \\\n",
        "  --one_shot\n",
        "\n",
        "##################### TO DELETE ###################################\n",
        "# You must replace YOUR_EXPERIMENT_ID with the value output from the previous\n",
        "# tensorboard `list` command or `upload` command.  For example\n",
        "# `tensorboard dev delete --experiment_id pQpJNh00RG2Lf1zOe9BrQA`\n",
        "\n",
        "## !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID_HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajiaCQK78KRb",
        "outputId": "af57b4b3-badd-4918-cd3b-e23b37994060"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-18 07:41:15.374601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/VlzYJpIpT9mzY79KZm7SyA/\n",
            "\n",
            "\u001b[1m[2023-04-18T07:41:17]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2023-04-18T07:41:25]\u001b[0m Total uploaded: 360 scalars, 372 tensors (258.5 kB), 6 binary objects (324.8 kB)\n",
            "\u001b[1m[2023-04-18T07:41:25]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/VlzYJpIpT9mzY79KZm7SyA/\n"
          ]
        }
      ]
    }
  ]
}