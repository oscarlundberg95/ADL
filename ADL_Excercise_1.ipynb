{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7Sf3Os6uqhUWkv0agZiGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarlundberg95/ADL/blob/main/ADL_Excercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download and prepare CIFAR-10 dataset*\n",
        "\n",
        "**Approach for image recogniztion**\n",
        "* Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
        "* Normalize the image pixel values (divide by 255)\n",
        "* One-Hot Encode the categorical column\n",
        "* Build a model architecture (Sequential) with Dense layers(Fully connected layers)\n",
        "* Train the model and make predictions"
      ],
      "metadata": {
        "id": "SeftxONs7UKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# loading cifar10 and shape + type assert to be sure\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# one-hot encoding categories\n",
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "# normalizing\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "i8YtgpRW7ahM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**All the models are the same except for optimizer and activation functions. As well as run with the same batch size of 128 and 10 epochs**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sS-Fwi0W7a64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeakyReLU + SGD\n",
        "## Results:\n"
      ],
      "metadata": {
        "id": "-uEmBGQUd7Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *Write a simple CNN network for classifying images*\n",
        "  - *use LeakyReLU as the activation function*\n",
        "  - *use SGD as the optimizer and 0.0001 as the learning rate, and keep all default param-eters*\n",
        "â€“ *Report the accuracy on the test set*"
      ],
      "metadata": {
        "id": "2p1P97VSfi54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='LeakyReLU', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='LeakyReLU'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='LeakyReLU'))\n",
        "\n",
        "# compiling the sequential model\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koKj8WLCDTrL",
        "outputId": "4994acbe-11ed-430c-9393-2311f40457e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 60s 152ms/step - loss: 6.8711 - accuracy: 0.1076 - val_loss: 9.5829 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "309/391 [======================>.......] - ETA: 12s - loss: 9.6074 - accuracy: 0.0995"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeakyReLU + Adam\n",
        "## Results:"
      ],
      "metadata": {
        "id": "uCzzL-VqeBId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Change the optimiser to Adam and run again the experiment. Report accuracy on test set.*\n"
      ],
      "metadata": {
        "id": "Ns5dVNa2DXMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='LeakyReLU', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='LeakyReLU'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='LeakyReLU'))\n",
        "\n",
        "# compiling the sequential model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "_jWTcgnvDZh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tanh + SGD\n",
        "## Results:"
      ],
      "metadata": {
        "id": "kLgM6v7SeYc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Swap the LeakyReLUs for Tanh. Then run again the experiment and report accuracy on test set. Make a separate file for this experiment.*\n"
      ],
      "metadata": {
        "id": "PuJVGNDoDcLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='tanh', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# compiling the sequential model\n",
        "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "FfJsj-aVDesD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tanh + Adam\n",
        "## Results:"
      ],
      "metadata": {
        "id": "n_qJl7uwepW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='tanh', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "# compiling the sequential model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# training the model for x epochs\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "I4RGEtC2ev00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualize the results of these runs on a Tensorboard. Just put any screenshot of the web interface with the experiments to prove you got it working is enough. (for example- show the training loss on tensorboard)*"
      ],
      "metadata": {
        "id": "61g1QKW8DfsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf ./logs/"
      ],
      "metadata": {
        "id": "3AQzW_KrDgQC"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}